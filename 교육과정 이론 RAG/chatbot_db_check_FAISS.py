from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
import streamlit as st
import os

def chatbot_db_check():
    st.title("ğŸ“š FAISS DB ì „ì²´ ë¬¸ì„œ ì¶œë ¥")

    # FAISS DB ê²½ë¡œ
    db_path = "./faiss_curriculum_index"

    if not os.path.exists(db_path):
        st.error("âŒ FAISS DB í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # Embedding ë° DB ë¡œë”©
    embedding = OpenAIEmbeddings(model="text-embedding-3-small")
    try:
        vectorstore = FAISS.load_local(db_path, embedding, allow_dangerous_deserialization=True)
        st.success("âœ… FAISS DB ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        st.error(f"âŒ DB ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # ì „ì²´ ë¬¸ì„œë¥¼ ëª¨ë‘ ì¶œë ¥í•˜ê¸° ìœ„í•´ FAISS ë‚´ë¶€ ì €ì¥ì†Œì—ì„œ ì§ì ‘ ì ‘ê·¼
    # -> _index_to_docstore_id, _docstore ë“±ì˜ ë‚´ë¶€ ì†ì„± ì‚¬ìš©
    doc_ids = list(vectorstore.index_to_docstore_id.values())
    docs = [vectorstore.docstore._dict[doc_id] for doc_id in doc_ids]

    st.text(f"ğŸ“„ ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")

    for i, doc in enumerate(docs, 1):
        st.markdown(f"### ğŸ“„ ë¬¸ì„œ {i}")
        st.text(doc.page_content[:1500])  # ìµœëŒ€ 1500ì ì¶œë ¥

    # ë¬¸ì„œ ì‚­ì œ (ì„ íƒì  ê¸°ëŠ¥)
    delete_id = st.sidebar.text_input("ì‚­ì œí•  ë¬¸ì„œì˜ ë‚´ë¶€ ID ì…ë ¥")
    if st.sidebar.button("ë¬¸ì„œ ì‚­ì œ"):
        try:
            vectorstore.delete([delete_id])
            vectorstore.save_local(db_path)
            st.success(f"âœ… ë¬¸ì„œ {delete_id} ì‚­ì œ ì™„ë£Œ")
        except Exception as e:
            st.error(f"âŒ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
