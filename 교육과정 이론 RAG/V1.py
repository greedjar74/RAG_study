'''
# RAG V1
- RAG ì‹œìŠ¤í…œ êµ¬ì¶•

ë¬¸ì œì 
- ë§¤ë²ˆ ì„ì‹œ DB ìƒì„± -> api ì‚¬ìš©ëŸ‰ ì¦ê°€
- í•œ ê°€ì§€ ì§ˆë¬¸ì—ë§Œ ë‹µë³€
'''

from langchain import hub
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.schema import Document
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
import sys
import os

# í™˜ê²½ ì„¤ì •
os.environ["OPENAI_API_KEY"] = ""  # ì‹¤ì œ í‚¤ë¡œ êµì²´í•˜ì„¸ìš”
sys.stdout.reconfigure(encoding='utf-8')

# PDF ë¶ˆëŸ¬ì˜¤ê¸° ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
reader = PdfReader("ì»¤ë¦¬í˜ëŸ¼ ì œì‘ ì°¸ê³ ìë£Œ.pdf")
text = "\n".join([page.extract_text() for page in reader.pages if page.extract_text()])

# í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
docs = [Document(page_content=chunk) for chunk in text_splitter.split_text(text)]

#ChromaDBì— ì²­í¬ë“¤ì„ ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ì €ì¥(OpenAI ì„ë² ë”© ëª¨ë¸ í™œìš©)
vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings(model = 'text-embedding-3-small'))
retriever = vectorstore.as_retriever()

# ëª¨ë¸ ë° prompt í˜•íƒœ ì„¤ì •
llm = ChatOpenAI(model='gpt-4o-mini')
prompt = hub.pull('rlm/rag-prompt')

#Retrieverë¡œ ê²€ìƒ‰í•œ ìœ ì‚¬ ë¬¸ì„œì˜ ë‚´ìš©ì„ í•˜ë‚˜ì˜ stringìœ¼ë¡œ ê²°í•©
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

query = 'íƒ€ì¼ëŸ¬ ëª¨í˜•ì´ ë­ì•¼?'

# ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ë° ì¶œë ¥
related_docs = retriever.invoke(query)
formatted_context = format_docs(related_docs)

print("ğŸ” ê´€ë ¨ ë¬¸ì„œ:\n")
print(formatted_context)
print("\nğŸ§  ë‹µë³€:\n")

# ë‹µë³€ ìƒì„±
answer = rag_chain.invoke(query)

# í•œ ë¬¸ì¥ì”© ì¤„ ë°”ê¿ˆ ì¶œë ¥
for sentence in answer.split('. '):
    print(sentence.strip())